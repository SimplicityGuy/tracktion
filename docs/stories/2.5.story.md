# Story 2.5: File Rename Proposal Service

## Story Information
- **Epic**: 2 - Metadata Analysis & Naming
- **Story Number**: 2.5
- **Status**: Draft
- **Created**: 2025-08-19
- **Updated**: 2025-08-19

## Story Statement
**As a** music collector,
**I want** a service that proposes new filenames based on extracted metadata and configurable patterns,
**so that** I can review and approve consistent, meaningful names for my music files before any actual renaming occurs.

## Acceptance Criteria
1. A new file_rename_proposal_service is created as a separate microservice or module within analysis_service.
2. The service generates filename proposals using configurable naming patterns with template syntax (e.g., "{artist} - {title} - {bpm}BPM").
3. Proposed filenames are validated for filesystem compatibility (removes invalid characters, handles length limits).
4. Each proposal includes:
   - Original filename and path
   - Proposed new filename
   - Confidence score based on metadata completeness
   - Potential conflicts or warnings
   - Preview of the full path with new name
5. Proposals are stored in the database with status tracking (pending, approved, rejected, applied).
6. The service detects and flags potential naming conflicts before any renaming occurs.
7. Different naming patterns can be configured based on file type or metadata conditions.
8. A batch proposal generation mode can process multiple files and store all proposals for later review.
9. The service exposes an API/message interface to retrieve pending proposals for UI consumption.
10. **NO actual file renaming occurs** - this service only generates and stores proposals.
11. Unit tests cover various naming patterns, edge cases, and conflict detection.

## Tasks / Subtasks

### 1. Create File Rename Proposal Service Module Structure (AC: 1)
- [ ] Create new module within analysis_service: `services/analysis_service/src/file_rename_proposal/`
- [ ] Create `__init__.py` with module exports
- [ ] Create `proposal_generator.py` for core proposal logic
- [ ] Create `pattern_manager.py` for handling naming patterns
- [ ] Create `validator.py` for filesystem compatibility validation
- [ ] Create `config.py` for service configuration

### 2. Implement Naming Pattern Engine (AC: 2, 7)
- [ ] Create template parser supporting pattern syntax: `{artist}`, `{title}`, `{album}`, `{bpm}`, etc.
- [ ] Implement conditional patterns based on metadata availability
- [ ] Support file type-specific patterns (MP3, FLAC, WAV, M4A)
- [ ] Create default pattern configurations
- [ ] Add custom pattern validation
- [ ] Write unit tests for pattern parsing and substitution

### 3. Implement Filesystem Validation (AC: 3)
- [ ] Create filesystem compatibility validator
  - [ ] Remove/replace invalid characters for Windows/Mac/Linux
  - [ ] Handle path length limits (255 chars for filename, full path limits)
  - [ ] Implement safe character replacement mapping
- [ ] Add Unicode normalization for special characters
- [ ] Create filename sanitization methods
- [ ] Write unit tests for edge cases and different OS requirements

### 4. Create Proposal Data Model and Storage (AC: 4, 5)
- [ ] Define database schema for proposals table:
  ```sql
  CREATE TABLE rename_proposals (
      id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
      recording_id UUID REFERENCES recordings(id),
      original_path TEXT NOT NULL,
      original_filename TEXT NOT NULL,
      proposed_filename TEXT NOT NULL,
      full_proposed_path TEXT NOT NULL,
      confidence_score DECIMAL(3,2),
      status VARCHAR(20) DEFAULT 'pending',
      conflicts TEXT[],
      warnings TEXT[],
      created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
      updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
  );
  ```
- [ ] Implement SQLAlchemy model for proposals
- [ ] Create repository methods for CRUD operations
- [ ] Add indexes for efficient querying
- [ ] Write integration tests for database operations

### 5. Implement Conflict Detection (AC: 6)
- [ ] Create conflict detection engine
  - [ ] Check for duplicate proposed filenames in same directory
  - [ ] Detect case-sensitivity conflicts (file.mp3 vs File.mp3)
  - [ ] Check against existing files in filesystem
  - [ ] Identify potential overwrites
- [ ] Implement conflict resolution strategies (append number, timestamp, etc.)
- [ ] Add warning generation for potential issues
- [ ] Write unit tests for various conflict scenarios

### 6. Create Confidence Scoring System (AC: 4)
- [ ] Implement confidence calculation based on:
  - [ ] Metadata completeness (required fields present)
  - [ ] Metadata quality (confidence scores from analysis)
  - [ ] Pattern match success rate
  - [ ] Conflict presence
- [ ] Create weighted scoring algorithm
- [ ] Add configurable confidence thresholds
- [ ] Write unit tests for scoring scenarios

### 7. Implement Batch Processing (AC: 8)
- [ ] Create batch proposal generator
  - [ ] Process multiple recordings in single operation
  - [ ] Implement progress tracking
  - [ ] Add transaction support for atomicity
- [ ] Optimize for performance with bulk operations
- [ ] Add batch validation before storage
- [ ] Write integration tests for batch operations

### 8. Create Message/API Interface (AC: 9)
- [ ] Define message schemas for:
  - [ ] Proposal generation requests
  - [ ] Proposal retrieval responses
  - [ ] Status update messages
- [ ] Implement RabbitMQ message handlers
- [ ] Create methods to retrieve proposals by:
  - [ ] Status (pending, approved, rejected)
  - [ ] Recording ID
  - [ ] Date range
  - [ ] Confidence threshold
- [ ] Add pagination support for large result sets
- [ ] Write integration tests for message handling

### 9. Integration with Analysis Pipeline (AC: 1, 10)
- [ ] Integrate with existing analysis_service message consumer
- [ ] Trigger proposal generation after metadata extraction completes
- [ ] Ensure NO actual file operations occur
- [ ] Add feature flag for enabling/disabling proposal generation
- [ ] Write integration tests with full pipeline

### 10. Comprehensive Testing and Documentation (AC: 11)
- [ ] Write unit tests achieving >80% coverage:
  - [ ] Pattern parsing and substitution
  - [ ] Filesystem validation
  - [ ] Conflict detection
  - [ ] Confidence scoring
  - [ ] Database operations
- [ ] Create integration tests for:
  - [ ] Full proposal generation flow
  - [ ] Message handling
  - [ ] Batch operations
- [ ] Add performance tests for large batches
- [ ] Document configuration options
- [ ] Create API documentation
- [ ] Run pre-commit hooks and fix issues

## Dev Notes

### Previous Story Insights
From Story 2.4 Musical Key and Mood Detection completion:
- **Service Architecture**: Clean module separation with dedicated components for each feature
- **Configuration Pattern**: Using dependency injection and configuration classes for flexibility
- **Database Pattern**: Using SQLAlchemy models with proper relationships and indexes
- **Message Handling**: Established patterns for RabbitMQ integration in message_consumer.py
- **Error Handling**: Comprehensive error handling with graceful degradation
- **Testing Approach**: Mock-based unit tests for deterministic results, integration tests for full flow
- **Type Safety**: Strict mypy compliance with proper type hints throughout
[Source: Story 2.4 Dev Agent Record]

### Data Models
**Metadata Model** (for reading existing metadata):
- `id`: UUID
- `recording_id`: Foreign key to Recording
- `key`: String (e.g., "artist", "title", "bpm", "key", "mood")
- `value`: String containing the metadata value
[Source: architecture/data-models-refined-and-finalized.md#metadata]

**Recording Model** (for referencing files):
- `id`: UUID
- `file_path`: Full path to file
- `file_name`: Current filename
[Source: architecture/data-models-refined-and-finalized.md#recording]

### File Locations
Based on project structure, new code should be created at:
- Main module: `services/analysis_service/src/file_rename_proposal/`
- Tests: `tests/unit/analysis_service/test_file_rename_proposal/`
- Integration tests: `tests/integration/test_rename_proposal_integration.py`
[Source: architecture/source-tree.md]

### Technical Constraints
- **Python Version**: Use Python 3.13 (per tech stack, though note Story 2.3 found 3.12 works better with Essentia)
- **Database**: PostgreSQL 17 with SQLAlchemy ORM
- **Messaging**: RabbitMQ 4.0 for inter-service communication
- **No Direct File Operations**: This service must NOT perform any actual file renaming
- **Pattern Syntax**: Use Python string.format() style templates for flexibility
[Source: architecture/tech-stack.md]

### Testing Requirements
- **Framework**: pytest with `uv run pytest` command
- **Coverage Goal**: Minimum 80% for new code
- **Test Location**: `tests/unit/analysis_service/` for unit tests
- **Pre-commit**: Must pass all hooks including ruff, mypy, formatting
- **Execution Pattern**:
  - Unit tests after each task: `uv run pytest tests/unit/analysis_service/test_file_rename_proposal/ -v`
  - Integration tests when available: `uv run pytest tests/integration/ -v`
  - Pre-commit before commits: `uv run pre-commit run --all-files`
[Source: architecture/test-strategy-and-standards.md]

### Configuration Management
Following the pattern from previous stories:
- Use configuration classes with dependency injection
- Support environment variables for sensitive configs
- Provide sensible defaults for development
- Document all configuration options
[Source: architecture/coding-standards.md#configuration]

## Project Structure Notes
This story creates a new module within the analysis_service, following the established pattern from Stories 2.3 and 2.4. The file_rename_proposal module will sit alongside the existing bpm_detector, key_detector, and mood_analyzer modules. It should follow the same architectural patterns: dependency injection, configuration management, comprehensive error handling, and integration with the existing message consumer infrastructure. The key difference is this service only generates proposals - it never performs actual file operations.

## Testing

### Testing Standards
- **Test Execution**: All tests must use `uv run pytest` (never `pytest` directly)
- **Test Location**: Unit tests in `tests/unit/analysis_service/test_file_rename_proposal/`
- **Test Naming**: Files named `test_*.py`
- **Coverage Goal**: Minimum 80% coverage for new code
- **Pre-commit**: Must pass all hooks before commit
  - Run: `uv run pre-commit run --all-files`
  - Includes: ruff linting, ruff formatting, mypy type checking
- **Task Completion**: Cannot mark task complete until:
  1. Implementation complete
  2. Unit tests written and passing
  3. Pre-commit hooks passing
  4. Code committed with descriptive message

### Story Completion Requirements
1. All tasks marked complete
2. All unit tests passing (`uv run pytest tests/unit/analysis_service/ -v`)
3. Integration tests passing (`uv run pytest tests/integration/ -v`)
4. Pre-commit hooks passing
5. Code coverage ≥80% for new code
6. Story documentation updated
7. All code committed and pushed

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-08-19 | 1.0 | Initial story creation from Epic 2 requirements | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
[To be populated by dev agent]

### Debug Log References
[To be populated by dev agent]

### Completion Notes
[To be populated by dev agent]

### File List
[To be populated by dev agent]

## QA Results
[To be populated by QA agent]
