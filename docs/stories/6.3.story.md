# Story 6.3: Automatic Tracklist Detection

## Story Information
- **Epic**: 6 - Tracklist Management
- **Story Number**: 6.3
- **Status**: Deferred
- **Created**: 2025-08-27
- **Updated**: 2025-08-28
- **Dependencies**: Stories 6.1 and 6.2 should be completed first for tracklist models and API structure
- **Note**: This story has been deferred to a future release. Automatic detection is not required for MVP.

## Story Statement
**As a** user with many mixes,
**I want** automatic tracklist detection attempts,
**So that** I can quickly catalog my collection.

## Acceptance Criteria
1. Audio fingerprinting attempts
2. Fuzzy matching against known tracks
3. Confidence scoring for matches
4. Manual verification workflow
5. Batch processing support

## Dev Notes

### Previous Story Insights
From Stories 6.1 and 6.2 implementation:
- Complete Tracklist and TrackEntry models with confidence scoring
- API structure established in `services/tracklist_service/src/api/`
- Draft management for manual verification workflow exists
- CUE generation integration functional
- Catalog search and matching patterns established
[Source: Stories 6.1 and 6.2 implementation context]

From Epic 2 (Metadata Analysis):
- Audio analysis capabilities exist in `services/analysis_service/src/`
- BPM detector (`bpm_detector.py`) and key detector (`key_detector.py`) available
- Batch processing infrastructure exists (`batch_processor.py`)
- Message-based processing via RabbitMQ established
[Source: Epic 2 implementation, file system inspection]

### Project Structure Requirements
Automatic detection will span multiple services:
- Analysis Service: `services/analysis_service/src/` (audio processing)
- Tracklist Service: `services/tracklist_service/src/` (tracklist management)
- Message Queue: RabbitMQ for async processing
- Cache: Redis for fingerprint caching
[Source: architecture/high-level-architecture.md]

### Data Models
**Using existing models with detection-specific fields**:
```python
class Tracklist:
    id: UUID
    audio_file_id: UUID
    source: str  # "auto-detected" for this story
    created_at: datetime
    updated_at: datetime
    tracks: List[TrackEntry]
    cue_file_id: Optional[UUID]
    confidence_score: float  # Overall detection confidence
    # Detection-specific fields:
    detection_method: Optional[str]  # "fingerprint", "metadata", "hybrid"
    requires_verification: bool = True  # Flag for manual review needed

class TrackEntry:
    position: int
    start_time: timedelta
    end_time: Optional[timedelta]
    artist: str
    title: str
    remix: Optional[str]
    label: Optional[str]
    catalog_track_id: Optional[UUID]
    confidence: float  # Individual track confidence
    transition_type: Optional[str]
    # Detection-specific fields:
    fingerprint_id: Optional[str]  # External fingerprint service ID
    match_method: Optional[str]  # "exact", "fuzzy", "partial"
    alternatives: Optional[List[Dict]]  # Alternative matches for manual review

class DetectionJob:
    id: UUID
    audio_file_id: UUID
    status: str  # "pending", "processing", "completed", "failed"
    created_at: datetime
    started_at: Optional[datetime]
    completed_at: Optional[datetime]
    result_tracklist_id: Optional[UUID]
    error_message: Optional[str]
    progress: int  # 0-100 percentage
```
[Source: docs/prd/epic-6-tracklist-management.md#Technical Scope, Stories 6.1-6.2]

### Audio Fingerprinting Strategy
**Implementation Approach**:
1. **Primary**: Use external service (e.g., AcoustID, Chromaprint) for fingerprinting
2. **Fallback**: Metadata-based matching using existing catalog
3. **Hybrid**: Combine fingerprint and metadata for better accuracy

**Fingerprinting Libraries/Services**:
- **Chromaprint**: Open-source audio fingerprinting (local processing)
- **AcoustID**: Web service for music identification
- **Essentia**: Audio analysis and music information retrieval
[Source: Industry standard audio fingerprinting solutions]

### Fuzzy Matching Algorithm
```python
# Fuzzy matching criteria:
matching_rules = {
    "artist_similarity_threshold": 0.85,  # Using Levenshtein distance
    "title_similarity_threshold": 0.85,
    "duration_tolerance_seconds": 10,
    "bpm_tolerance": 2,  # If BPM available
    "key_compatibility": True,  # If key available
    "confidence_weights": {
        "fingerprint": 0.5,
        "metadata": 0.3,
        "duration": 0.1,
        "audio_features": 0.1
    }
}
```
[Source: Best practices for audio matching]

### API Specifications
**REST Endpoints to Implement**:
```
# Detection Job Management
POST /api/v1/tracklists/detect
  - Body: { audio_file_id: "...", method: "auto|fingerprint|metadata" }
  - Returns: Detection job ID

GET /api/v1/tracklists/detect/jobs/{job_id}
  - Returns: Job status and progress

GET /api/v1/tracklists/detect/jobs
  - Query params: status, date_range, audio_file_id
  - Returns: List of detection jobs

# Detection Results
GET /api/v1/tracklists/detect/results/{job_id}
  - Returns: Detected tracklist with confidence scores

POST /api/v1/tracklists/detect/verify/{tracklist_id}
  - Body: { tracks: [...verified/corrected tracks...] }
  - Returns: Updated tracklist with verification status

# Alternative Matches
GET /api/v1/tracklists/{id}/tracks/{position}/alternatives
  - Returns: Alternative match suggestions for manual selection

POST /api/v1/tracklists/{id}/tracks/{position}/select-alternative
  - Body: { alternative_index: int }
  - Returns: Updated track with selected alternative

# Batch Processing
POST /api/v1/tracklists/detect/batch
  - Body: { audio_file_ids: [...], method: "auto" }
  - Returns: Batch job ID

GET /api/v1/tracklists/detect/batch/{batch_id}
  - Returns: Batch job status and individual job progress
```
[Source: docs/prd/epic-6-tracklist-management.md#API Specification]

### Analysis Service Integration
**New Analysis Components**:
- Audio fingerprinting module: `services/analysis_service/src/fingerprint_analyzer.py`
- Track boundary detection: `services/analysis_service/src/track_segmentation.py`
- Silence/transition detection: `services/analysis_service/src/transition_detector.py`
[Source: Extension of existing analysis service patterns]

### Message Queue Workflow
```yaml
Detection Flow:
  1. API receives detection request
  2. Publish "DETECTION_REQUESTED" message to RabbitMQ
  3. Analysis service consumes message
  4. Analysis service performs fingerprinting/analysis
  5. Publish "DETECTION_COMPLETED" message with results
  6. Tracklist service creates tracklist from results
  7. Publish "VERIFICATION_REQUIRED" if confidence < threshold
```
[Source: architecture/high-level-architecture.md#Event-Driven Communication]

### Confidence Scoring Algorithm
```python
def calculate_confidence(match_data: Dict) -> float:
    """
    Calculate confidence score for track match.
    Returns: float between 0.0 and 1.0
    """
    base_confidence = 0.0

    # Fingerprint match (50% weight)
    if match_data.get('fingerprint_match'):
        base_confidence += 0.5 * match_data['fingerprint_score']

    # Metadata match (30% weight)
    if match_data.get('metadata_match'):
        artist_sim = match_data['artist_similarity']
        title_sim = match_data['title_similarity']
        base_confidence += 0.3 * ((artist_sim + title_sim) / 2)

    # Duration match (10% weight)
    if match_data.get('duration_match'):
        duration_accuracy = match_data['duration_accuracy']
        base_confidence += 0.1 * duration_accuracy

    # Audio features (10% weight)
    if match_data.get('audio_features'):
        feature_match = match_data['audio_feature_score']
        base_confidence += 0.1 * feature_match

    return min(base_confidence, 1.0)
```

### Technical Constraints
- Audio processing should handle files up to 500MB
- Fingerprinting timeout: 60 seconds per track
- Batch processing: Maximum 50 files per batch
- Processing time target: <30s per mix (Epic 6 success metric)
- Confidence threshold for auto-acceptance: 0.8
- Memory limit for audio processing: 2GB per worker
[Source: architecture/coding-standards.md, Epic 6 success metrics]

### File Locations
Based on project structure, new code should be created in:

**Analysis Service**:
- Fingerprinting: `services/analysis_service/src/fingerprint_analyzer.py` (new)
- Segmentation: `services/analysis_service/src/track_segmentation.py` (new)
- Transition detection: `services/analysis_service/src/transition_detector.py` (new)
- Tests: `tests/unit/analysis_service/test_fingerprint_analyzer.py` (new)

**Tracklist Service**:
- Detection API: `services/tracklist_service/src/api/detection_endpoints.py` (new)
- Detection service: `services/tracklist_service/src/services/detection_service.py` (new)
- Verification service: `services/tracklist_service/src/services/verification_service.py` (new)
- Job manager: `services/tracklist_service/src/services/detection_job_manager.py` (new)
- Tests: `tests/unit/tracklist_service/test_detection_endpoints.py` (new)

## Tasks / Subtasks

- [ ] **Task 1: Extend Models for Detection** (AC: 3)
  - [ ] Update Tracklist model with detection-specific fields
  - [ ] Create DetectionJob model for job tracking
  - [ ] Add alternatives field to TrackEntry for manual selection
  - [ ] Create Alembic migration for new fields
  - [ ] Run migration with `uv run alembic upgrade head`
  - [ ] Write unit tests for model changes

- [ ] **Task 2: Implement Audio Fingerprinting** (AC: 1)
  - [ ] Create `services/analysis_service/src/fingerprint_analyzer.py`
  - [ ] Integrate Chromaprint library for local fingerprinting
  - [ ] Implement AcoustID API client for web service
  - [ ] Add fallback between local and web service
  - [ ] Cache fingerprints in Redis to avoid re-processing
  - [ ] Write unit tests for fingerprinting module

- [ ] **Task 3: Implement Track Segmentation** (AC: 1, 2)
  - [ ] Create `services/analysis_service/src/track_segmentation.py`
  - [ ] Detect silence and transitions between tracks
  - [ ] Use audio energy analysis for boundary detection
  - [ ] Estimate track start/end times
  - [ ] Handle continuous mixes vs. separate tracks
  - [ ] Write unit tests for segmentation

- [ ] **Task 4: Create Fuzzy Matching System** (AC: 2)
  - [ ] Implement fuzzy string matching for artist/title
  - [ ] Use Levenshtein distance for similarity scoring
  - [ ] Implement duration-based matching
  - [ ] Combine BPM and key data when available
  - [ ] Create matching rules configuration
  - [ ] Write unit tests for fuzzy matching

- [ ] **Task 5: Implement Confidence Scoring** (AC: 3)
  - [ ] Create confidence calculation algorithm
  - [ ] Weight different match factors appropriately
  - [ ] Set thresholds for auto-acceptance vs. manual review
  - [ ] Generate overall tracklist confidence score
  - [ ] Store individual track confidence scores
  - [ ] Write unit tests for confidence scoring

- [ ] **Task 6: Create Detection Job Manager** (AC: 5)
  - [ ] Create `services/tracklist_service/src/services/detection_job_manager.py`
  - [ ] Implement job creation and tracking
  - [ ] Add progress monitoring and updates
  - [ ] Handle job failures and retries
  - [ ] Implement job status queries
  - [ ] Write unit tests for job management

- [ ] **Task 7: Implement Detection API Endpoints** (AC: 1, 5)
  - [ ] Create `services/tracklist_service/src/api/detection_endpoints.py`
  - [ ] Implement single file detection endpoint
  - [ ] Implement batch detection endpoint
  - [ ] Add job status and progress endpoints
  - [ ] Implement results retrieval endpoint
  - [ ] Write API tests with pytest

- [ ] **Task 8: Create Verification Service** (AC: 4)
  - [ ] Create `services/tracklist_service/src/services/verification_service.py`
  - [ ] Implement manual verification workflow
  - [ ] Store alternative matches for user selection
  - [ ] Handle track corrections and confirmations
  - [ ] Update confidence scores after verification
  - [ ] Write unit tests for verification

- [ ] **Task 9: Implement Message Queue Integration**
  - [ ] Create RabbitMQ message schemas for detection workflow
  - [ ] Implement message publishers in tracklist service
  - [ ] Implement message consumers in analysis service
  - [ ] Add error handling and dead letter queues
  - [ ] Ensure idempotent message processing
  - [ ] Write integration tests for message flow

- [ ] **Task 10: Add Batch Processing Support** (AC: 5)
  - [ ] Implement batch job orchestration
  - [ ] Add parallel processing for multiple files
  - [ ] Implement progress tracking for batch jobs
  - [ ] Add batch size limits and validation
  - [ ] Handle partial batch failures gracefully
  - [ ] Write tests for batch processing

- [ ] **Task 11: Performance Optimization**
  - [ ] Optimize fingerprinting for large files
  - [ ] Implement caching strategy for common tracks
  - [ ] Add database indexes for detection queries
  - [ ] Ensure <30s processing time per mix
  - [ ] Monitor memory usage during processing
  - [ ] Write performance tests

- [ ] **Task 12: Run All Tests and Validation**
  - [ ] Run all unit tests: `uv run pytest tests/unit/ -v`
  - [ ] Run integration tests if services available
  - [ ] Run pre-commit hooks: `uv run pre-commit run --all-files`
  - [ ] Ensure mypy type checking passes: `uv run mypy`
  - [ ] Verify code coverage meets 80% threshold
  - [ ] Test with various audio file formats and sizes

## Testing Standards
[Source: architecture/test-strategy-and-standards.md]

- **Framework**: Use `pytest` with `uv run pytest` execution
- **Test Files**: Place in appropriate `tests/unit/` subdirectories
- **Coverage Goal**: Minimum 80% for new code
- **Test Types**: Unit tests, integration tests for message flow
- **Performance Tests**: Verify <30s processing per mix
- **Test Data**: Use sample audio files of various formats
- **Pre-commit**: Must pass all hooks before committing

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-08-27 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record

### Agent Model Used
(To be populated by Dev Agent)

### Debug Log References
(To be populated by Dev Agent)

### Completion Notes
(To be populated by Dev Agent)

### File List
(To be populated by Dev Agent)

## QA Results
(To be populated by QA Agent)
